package org.irisacsee.trajlab.query;

import com.google.protobuf.ByteString;
import lombok.extern.slf4j.Slf4j;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.sql.SparkSession;
import org.irisacsee.trajlab.index.type.ByteArray;
import org.irisacsee.trajlab.index.type.RowKeyRange;
import org.irisacsee.trajlab.meta.DataSetMeta;
import org.irisacsee.trajlab.meta.IndexMeta;
import org.irisacsee.trajlab.model.Trajectory;
import org.irisacsee.trajlab.query.condition.AbstractQueryCondition;
import org.irisacsee.trajlab.query.coprocessor.autogenerated.QueryCondition;
import org.irisacsee.trajlab.store.IndexTable;

import java.io.IOException;
import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;

/**
 * 抽象查询，QC为设计时考虑的所有条件
 *
 * @author irisacsee
 * @since 2024/11/22
 */
@Slf4j
public abstract class AbstractQuery<QC extends AbstractQueryCondition> implements Serializable {
    protected DataSetMeta dataSetMeta;
    protected transient IndexTable target;  // 目标索引表不做约束，某些查询可能会有更优的索引
    protected final QC condition;

    public AbstractQuery(DataSetMeta dataSet, QC condition) {
        this.dataSetMeta = dataSet;
        this.condition = condition;
    }

    protected AbstractQuery(IndexTable target, QC condition) {
        this.target = target;
        this.condition = condition;
    }

    protected void setupTarget() throws IOException {
        if (target == null) {
            IndexMeta indexMeta = findBestIndex();
            log.info("Query [{}] will be executed on table: {}",
                    getQueryInfo(), indexMeta.getIndexTableName());
            target = new IndexTable<>(indexMeta);
        }
    }

    public List<RowKeyRange> getIndexRanges() throws IOException {
        setupTarget();
        return target
                .getIndexMeta()
                .getIndexStrategy()
                .getScanRanges(condition);
    }

    public List<RowKeyRange> getPartitionedIndexRanges() throws IOException {
        setupTarget();
        return target
                .getIndexMeta()
                .getIndexStrategy()
                .getPartitionedScanRanges(condition);
    }

    /**
     * 根据所有索引范围进行查询
     *
     * @return 查询结果
     * @throws IOException 抛出IO异常
     */
    public List<Trajectory> run() throws IOException {
        return execute(getIndexRanges());
    }

    /**
     * 根据分区索引范围进行查询
     *
     * @return 查询结果
     * @throws IOException 抛出IO异常
     */
    public List<Trajectory> runPartitioned() throws IOException {
        return execute(getPartitionedIndexRanges());
    }

    /**
     * 使用Spark根据分区索引范围进行查询
     *
     * @param ss SparkSession
     * @return 查询结果
     * @throws IOException 抛出IO异常
     */
    public List<Trajectory> runBySpark(SparkSession ss) throws IOException {
        List<RowKeyRange> ranges = getPartitionedIndexRanges();
        JavaSparkContext sc = new JavaSparkContext(ss.sparkContext());
        return sc.parallelize(ranges)
                .groupBy(RowKeyRange::getShardKey)
                .flatMap(pair -> {
                    List<RowKeyRange> rkRanges = new ArrayList<>();
                    pair._2.forEach(rkRanges::add);
                    return execute(rkRanges).iterator();
                })
                .collect();
    }

    protected List<QueryCondition.Range> rowKeyRangeToProtoRange(List<RowKeyRange> rkRanges) {
        List<QueryCondition.Range> ranges = new ArrayList<>(rkRanges.size());
        for (RowKeyRange rkRange : rkRanges) {
            ranges.add(QueryCondition.Range
                    .newBuilder()
                    .setStart(ByteString.copyFrom(rkRange.getStartKey()))
                    .setEnd(ByteString.copyFrom(rkRange.getEndKey()))
                    .setContained(rkRange.isValidate())
                    .build());
        }
        ranges.sort((o1, o2) -> {
            byte[] o1Start = o1.getStart().toByteArray();
            byte[] o2Start = o2.getStart().toByteArray();
            byte[] o1End = o1.getEnd().toByteArray();
            byte[] o2End = o2.getEnd().toByteArray();
            int c = ByteArray.compare(o1Start, o2Start);
            return c == 0 ? ByteArray.compare(o1End, o2End) : c;
        });
        return ranges;
    }

    // 这里面能实现比较复杂的逻辑，比如根据数据的时空分布、主副索引的性能差异、查询条件对不同维度的侧重点，选择恰当的index。
    // 当下是一个最简单的逻辑：找到对应查询适合的索引，从里面选一个主索引，避免多次回表查询。
    protected abstract IndexMeta findBestIndex();

    protected abstract String getQueryInfo();

    protected abstract List<Trajectory> execute(List<RowKeyRange> rkRanges) throws IOException;
}
